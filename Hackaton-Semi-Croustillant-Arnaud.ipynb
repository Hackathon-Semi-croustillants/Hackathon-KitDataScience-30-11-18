{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hackathon KitDatascience 30/11/2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Groupe</b> : semi croustillants <br>\n",
    "<b>Membres</b> :\n",
    "<ul>\n",
    "    <li>Abdelfattah Abouelaoualim</li>\n",
    "    <li>Arnaud Lejeune</li>\n",
    "    <li>Valentin Larrieu</li>\n",
    "    <li>Thomas Meimoun</li>\n",
    "    <li>Thibault Royet</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "# notebook\n",
    "\n",
    "# text formatting\n",
    "import re\n",
    "# slugify?\n",
    "\n",
    "import requests, json, logging\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "from statistics import mean\n",
    "import json\n",
    "import time\n",
    "import unittest\n",
    "\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "\n",
    "# sklearn\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Vizualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED=1234\n",
    "website_prefix = \"https://www.uuu.com\"\n",
    "file_path = \"path\\\\file.csv\" # used in get_import_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global fuctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if there is usefull function, put it there"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Harvesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.post('https://accounts.spotify.com/api/token', headers = {'Authorization': 'Basic NDM0YmFiM2VhNmM2NDg2MmI3NmJkYWUwOTA0NmU2Njg6ZjFlZmFhZmM5MjA1NDFiYzkyZGNlMTk2MzBhZjk1NzE='}, data= {'grant_type': 'client_credentials'})\n",
    "token = 'Bearer {}'.format(r.json()['access_token'])\n",
    "headers = {'Authorization': token, \"Accept\": 'application/json', 'Content-Type': \"application/json\"}\n",
    "\n",
    "ids = ['5bFSM9nsguVNQ3XWl85Xfw', '2pOYGbN8DUAxnODGIEBoV5', '15uk1tKzqruIL9rpz2s0Fl', \\\n",
    "       '6TGxmQCgNUC3Q4OvmFO3Sd', '5HJvAgJ4dq04J8QNECSMgW', '65m3oZRKaqr3toK5tGsPgI', \\\n",
    "       '10tuG36GBGTcHMM0Csztr6', '43z6vekkutesDQuE09YgTC', '4fBgDAfXB18MwDFIShbosT', \\\n",
    "       '6MgrQVyvHZMyCeJ7Sxv1tN', '33om8TB2O2WDWKuYWy5uul', '0eUpvlNtDK8O6KsHrfnZGB', \\\n",
    "       '5Nu0GvqBqDAafZh4f9pu6r', '4z46p4KKei3Yl7ESDGvKUX', '6YHctphM95Ut3QDDi80rNX', \\\n",
    "       '3dbnOMK5OBxdOotlqlR0Yn', '2wkWbYyG1V7Rk10IHEFdcM', '3He6XDiKnWYVeytCg5pQkX', \\\n",
    "       '6mroxUZC53t1IuG51IQArA', '1FoTMVVo5dYodKSQ2sbbNU', '33Bi8ANiwnqc7ywivNp5jx', \\\n",
    "       '6vg1AH4z5uIsTXw0sKCsCo', '6Pi3jayiuzwmA5i6tLtIap', '52C6pPOr0eD8gqNyw44XbA', \\\n",
    "       '2DpRAKsc8kVq3GaZ9LKaoC', '2ULKV3rHKIftTjMoAOmfXX', '3lZdTHEpGPq54u27Ua7WIE', \\\n",
    "       '1iauAKKxAC2z6ROVsDa6bP', '53byZgkL7wTapZtAi0F7Fq', '0RyVZogDYd0idCobW26ZrS', \\\n",
    "       '4w9GmPTTwnMpy92GWsxjhB', '3CFT1NRuFvfsopqKQIg1vJ', '2JRDd2X0iFeLbsbbuxxQAX', \\\n",
    "       '2pChXx1LvrCdZjYz8jlDM7', '0Tepm79mcnwx7vFvi9HtuY', '3u2OH9RlcW93sCa3evYEZ3', \\\n",
    "       '6CqIdVcjiJ8gCMnxB3bRyn', '7cy4KaiS55QNcpHrz1HqtQ', '3hRrX6oWktgVmbx5j2fMjd', \\\n",
    "       '7auFWvzOAbWRpbujMWQnsm', '6UKMRL5QvJZrnGMPlau7Xf', '6TGxmQCgNUC3Q4OvmFO3Sd', \\\n",
    "       '3VrMXpO15HIyoKnWNrn93g', '2fjNigiRQP0caIFvRLSmtP', '0I0UVxYhclAbTZJMOKSMRd', \\\n",
    "       '3b887Yi8a6Ila2HQ0Tip1E', '51XM6KD165hLu5QmIWY1El', '2DjIfVDXGYDgRxw7IJTKVb', \\\n",
    "       '4AnAUkQNrLKlJCInZGSXRO', '3fdBeP9fqqPycGSxxBn3Wl', '7Fz1jJnAe5d4NHvx0VoiU3', \\\n",
    "       '6NQWcYcx5oTew4UG5J67UK', '16LsUp1bSPTKCb5X81kHnB', '37i9dQZEVXbMDoHDwVN2tF']\n",
    "i = ids[0]\n",
    "track_ids = []\n",
    "\n",
    "for i in ids :\n",
    "    stop = False\n",
    "    url = f'https://api.spotify.com/v1/playlists/{i}/tracks'\n",
    "\n",
    "    while not stop :\n",
    "        res = requests.get(url, params = {}, headers = headers)\n",
    "\n",
    "        if res.status_code != 200 :\n",
    "            print('Error')\n",
    "            stop = True\n",
    "\n",
    "        else :\n",
    "            items = res.json()['items']\n",
    "            for item in items :\n",
    "                track_ids.append(item['track']['id']) \n",
    "\n",
    "            if res.json()['next'] == None or res.json()['next'] == 'null' :\n",
    "                stop = True\n",
    "            else :\n",
    "                url = res.json()['next']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19379"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(track_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12912"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(track_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_analysis(track_id, headers):\n",
    "\n",
    "    res = requests.get('https://api.spotify.com/v1/audio-analysis/{}'.format(track_id), headers = headers)\n",
    "    res = res.json()['track']\n",
    "    duration = res['duration']\n",
    "    end_fade = res['end_of_fade_in']\n",
    "    key = res['key']\n",
    "    key_con = res['key_confidence']\n",
    "    loud = res['loudness']\n",
    "    mode = res['mode']\n",
    "    mode_con = res['mode_confidence']\n",
    "    start_fade = res['start_of_fade_out']\n",
    "    temp = res['tempo']\n",
    "    time_sig = res['time_signature']\n",
    "    time_sig_con = res['time_signature_confidence']\n",
    "    \n",
    "    \n",
    "    return pd.to_numeric(pd.Series({'duration': duration, \n",
    "                    'key': key,\n",
    "                     'loudness': loud,\n",
    "                     'mode': mode,\n",
    "                     'tempo': temp,\n",
    "                     'end_of_fade_in': end_fade,\n",
    "                     'start_of_fade_out': start_fade,\n",
    "                     'mode_confidence': mode_con,\n",
    "                     'key_confidence': key_con,\n",
    "                     'time_signature': time_sig,\n",
    "                     'time_signature_confidence': time_sig_con}))\n",
    "\n",
    "def get_headers(access_token):\n",
    "    r = requests.post('https://accounts.spotify.com/api/token', headers = {'Authorization': 'Basic NDM0YmFiM2VhNmM2NDg2MmI3NmJkYWUwOTA0NmU2Njg6ZjFlZmFhZmM5MjA1NDFiYzkyZGNlMTk2MzBhZjk1NzE='}, data= {'grant_type': 'client_credentials'})\n",
    "    token = 'Bearer {}'.format(r.json()['access_token'])\n",
    "    headers = {'Authorization': token, \"Accept\": 'application/json', 'Content-Type': \"application/json\"}\n",
    "    \n",
    "    return headers\n",
    "\n",
    "def get_artist_features(artist_id, headers):\n",
    "    \n",
    "    res = requests.get('https://api.spotify.com/v1/artists/{}'.format(artist_id), headers = headers)\n",
    "    artist_hot = res.json()['popularity']/100\n",
    "    \n",
    "    pass\n",
    "\n",
    "def get_features(track_id, headers):\n",
    "\n",
    "    res = requests.get('https://api.spotify.com/v1/audio-features/{}'.format(track_id), headers = headers)\n",
    "    res = res.json()\n",
    "    key = res['key']\n",
    "    mode = res['mode']\n",
    "    time_sig = res['time_signature']\n",
    "    loud = res['loudness']\n",
    "    acousticness = res['acousticness']\n",
    "    danceability = res['danceability']\n",
    "    energy = res['energy']\n",
    "    instrumentalness = res['instrumentalness']\n",
    "    liveness = res['liveness']\n",
    "    speechiness = res['speechiness']\n",
    "    valence = res['valence']\n",
    "    tempo = res['tempo']\n",
    "    \n",
    "    \n",
    "    return pd.to_numeric(pd.Series({'key': key,\n",
    "                     'mode': mode,\n",
    "                     'time_signature': time_sig,\n",
    "                     'loudness': loud,\n",
    "                     'acousticness': acousticness,\n",
    "                     'danceability': danceability,\n",
    "                     'energy': energy,\n",
    "                     'instrumentalness': instrumentalness,\n",
    "                     'liveness': liveness,\n",
    "                     'speechiness': speechiness,\n",
    "                     'valence': valence,\n",
    "                     'tempo': tempo}))\n",
    "\n",
    "def get_several_features(track_ids, headers):\n",
    "    str_track_ids = str(track_ids)[1:-1].replace(\" \", \"\").replace(\"\\'\", \"\")\n",
    "    res = requests.get('https://api.spotify.com/v1/audio-features/?ids={}'.format(str_track_ids), headers = headers)\n",
    "    res = res.json()\n",
    "    return pd.DataFrame.from_dict(res['audio_features'], dtype = None)  \n",
    "\n",
    "def get_several_tracksAttributes(track_ids, headers):\n",
    "    str_track_ids = str(track_ids)[1:-1].replace(\" \", \"\").replace(\"\\'\", \"\")\n",
    "    print(str_track_ids)\n",
    "    res = requests.get('https://api.spotify.com/v1/tracks/?ids={}'.format(str_track_ids), headers = headers)\n",
    "    res = res.json()\n",
    "    return pd.DataFrame.from_dict(res['tracks'])  \n",
    "  \n",
    "def get_several_artistAttributes(artist_ids, headers):\n",
    "    str_artist_ids = str(artist_ids)[1:-1].replace(\" \", \"\").replace(\"\\'\", \"\")\n",
    "    print(str_artist_ids)\n",
    "    res = requests.get('https://api.spotify.com/v1/artists?ids={}'.format(str_artist_ids), headers = headers)\n",
    "    res = res.json()\n",
    "    return pd.DataFrame.from_dict(res['artists'])\n",
    "\n",
    "def transform_followers_to_nb(df):\n",
    "    pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12912"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "track_ids = list(set(track_ids))\n",
    "len(track_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.post('https://accounts.spotify.com/api/token', headers = {'Authorization': 'Basic NDM0YmFiM2VhNmM2NDg2MmI3NmJkYWUwOTA0NmU2Njg6ZjFlZmFhZmM5MjA1NDFiYzkyZGNlMTk2MzBhZjk1NzE='}, data= {'grant_type': 'client_credentials'})\n",
    "token = 'Bearer {}'.format(r.json()['access_token'])\n",
    "headers = {'Authorization': token, \"Accept\": 'application/json', 'Content-Type': \"application/json\"}\n",
    "\n",
    "stop = False\n",
    "df = get_several_features(track_ids[:100], headers)\n",
    "i = 1\n",
    "\n",
    "while not stop :\n",
    "    ids = track_ids[i*100 : (i+1)*100]\n",
    "    try:\n",
    "        df = df.append(get_several_features(ids, headers))\n",
    "    except :\n",
    "        pass\n",
    "    i+=1\n",
    "    if i > len(track_ids)//100 :\n",
    "        stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12812, 18)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrap the website *** to give a usefull dataframe\n",
    "\n",
    "def get_scrap_dataframe():\n",
    "\n",
    "    # TBD\n",
    "    \"\"\"\n",
    "    # CODE EXAMPLE\n",
    "    \n",
    "    url = website_prefix + \"\" #\n",
    "    soup = _handle_request_result_and_build_soup(url)\n",
    "\n",
    "    specific_class = \"search-table-data\"\n",
    "    tableContent =soup.find(class_=specific_class).find_all(\"tr\")\n",
    "    mylinks =[]\n",
    "    for ind in range (1,len(tableContent)):\n",
    "        mylinks.append(_clear_url(tableContent[ind].attrs['onclick']))\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the *** api to get usefull dataframe\n",
    "\n",
    "def get_api_dataframe():\n",
    "\n",
    "    # TBD\n",
    "    \"\"\"\n",
    "    # CODE EXAMPLE\n",
    "    \n",
    "    # We read the token which is stored in a local file\n",
    "    token = open(\"PATH\\\\gitToken.txt\", encoding=\"utf8\").readline()[:-1]\n",
    "    \n",
    "    request = requests.get(\"https://api.github.com/users/\" + username + \"/repos\", auth=(username_account, token))\n",
    "    #print(\"request code \", request.status_code)\n",
    "    \n",
    "    json_res = json.loads(request.text)\n",
    "    #print(\"jsonres\", json_res)\n",
    "    \n",
    "    try:\n",
    "        star_list = [json1[\"stargazers_count\"] for json1 in json_res]\n",
    "        dict[username] = mean(star_list)\n",
    "    except:\n",
    "        dict[username] = 0\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data from a csv file\n",
    "\n",
    "def get_import_dataframe():\n",
    "\n",
    "    # TBD\n",
    "    \"\"\"\n",
    "    #CODE EXAMPLE \n",
    "    \n",
    "    na_values = ['?', '']\n",
    "    \n",
    "    path = \"path\\\\file.csv\" #dataset insee\n",
    "    \n",
    "    # We import the dataframe\n",
    "    df = pd.read_csv(file_path, sep=',', na_values=na_values) # add chunksize=1000 to limit the size then df = next(df)\n",
    "    \"\"\"\n",
    "\n",
    "    # use the global variable file_path to define the path\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Data joining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the data of the 3 dataframe\n",
    "\n",
    "def get_joined_dataframe(df_scrap, df_api, df_import):\n",
    "    \n",
    "    # TBD\n",
    "    \n",
    "    \"\"\"\n",
    "    # CODE EXAMPLE\n",
    "    \n",
    "    joined_df_with_pop = pd.merge(joined_df, population_filtered, on='DEPARTEMENTID', left_index=True, right_index=False)\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    return df   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the dataframe\n",
    "\n",
    "def get_cleaned_dataframe(df_in):\n",
    "    \n",
    "    # TBD\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    return df  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Vizualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot an interesting thing\n",
    "\n",
    "def vizualise_interesting_thing_1(df_in):\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # CODE EXAMPLE\n",
    "    \n",
    "    plot_pop_depassement = df_in.plot(x='POPULATION', y='POURCENTAGE_DEPASSEMENT', marker='o', color='red', title = \"POPULATION as a function of POURCENTAGE_DEPASSEMENT\")\n",
    "    plt.show()\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results of the model\n",
    "\n",
    "def plot_my_model(model):\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Explotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a model on the data\n",
    "\n",
    "def build_a_model(df_in):\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # CODE EXAMPLE\n",
    "    \n",
    "    X = spe[\"EFFECTIFS/POPULATION\"]\n",
    "    Y = spe[\"POURCENTAGE_DEPASSEMENT\"]\n",
    "\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.2, random_state=SEED)\n",
    "    skl_lm = linear_model.LinearRegression(fit_intercept=True)\n",
    "    skl_lm.fit(X_train, Y_train)\n",
    "    score = skl_lm.score(X_test, Y_test)\n",
    "    print(\"Score: \\n\", score)\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test definition & main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start \n",
      "\n",
      "End \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.009s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "class HackathonTests(unittest.TestCase):\n",
    "\n",
    "    def test_dummy(self):\n",
    "        self.assertEqual('foo'.upper(), 'FOO')\n",
    "        \n",
    "    def test_return_type(self):\n",
    "        self.assertEqual(type(get_scrap_dataframe()), type(pd.DataFrame()))    \n",
    "        self.assertEqual(type(get_api_dataframe()), type(pd.DataFrame()))\n",
    "        self.assertEqual(type(get_import_dataframe()), type(pd.DataFrame()))\n",
    "        self.assertEqual(type(get_joined_dataframe(pd.DataFrame(),pd.DataFrame(),pd.DataFrame())), type(pd.DataFrame()))\n",
    "        self.assertEqual(type(get_cleaned_dataframe(pd.DataFrame())), type(pd.DataFrame()))\n",
    "        self.assertEqual(type(vizualise_interesting_thing_1(pd.DataFrame())), type(None))\n",
    "        self.assertEqual(type(build_a_model(pd.DataFrame())), type(None))\n",
    "        self.assertEqual(type(plot_my_model(pd.DataFrame())), type(None))\n",
    "        \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    unittest.main(argv=['first-arg-is-ignored'], exit=False)\n",
    "\n",
    "def main():\n",
    "    print(\"Start \\n\")\n",
    "\n",
    "\n",
    "    ########## GET DATA FROM SOURCES\n",
    "    \n",
    "    # Scrapp\n",
    "    df_scrap = get_scrap_dataframe()\n",
    "    \n",
    "    # Api\n",
    "    df_api = get_api_dataframe()\n",
    "    \n",
    "    # Import\n",
    "    df_import = get_import_dataframe()\n",
    "    \n",
    "    #########\n",
    "    \n",
    "    \n",
    "    \n",
    "    ########## DATA JOINING\n",
    "    \n",
    "    df_joined = get_joined_dataframe(df_scrap, df_api, df_import)\n",
    "    \n",
    "    \n",
    "    ########\n",
    "    \n",
    "    \n",
    "    ########## DATA CLEANING (after or before join depending on data)\n",
    "    \n",
    "    df_cleaned = get_cleaned_dataframe(df_joined)\n",
    "    \n",
    "    #########\n",
    "    \n",
    "    \n",
    "    ########## DATA VISUALISATION\n",
    "    \n",
    "    vizualise_interesting_thing_1(df_cleaned)\n",
    "    \n",
    "    #########\n",
    "    \n",
    "    ########## DATA EXPLOTATION\n",
    "    \n",
    "    # Use model to predict\n",
    "    \n",
    "    model_built = build_a_model(df_cleaned)\n",
    "    \n",
    "    plot_my_model(model_built)\n",
    "    \n",
    "    \n",
    "    #########\n",
    "    \n",
    "\n",
    "    print(\"End \\n\")\n",
    "\n",
    "\n",
    "main()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
