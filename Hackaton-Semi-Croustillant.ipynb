{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hackathon KitDatascience 30/11/2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Groupe</b> : semi croustillants <br>\n",
    "<b>Membres</b> :\n",
    "<ul>\n",
    "    <li>Abdelfattah Abouelaoualim</li>\n",
    "    <li>Arnaud Lejeune</li>\n",
    "    <li>Valentin Larrieu</li>\n",
    "    <li>Thomas Meimoun</li>\n",
    "    <li>Thibault Royet</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "# notebook\n",
    "\n",
    "# text formatting\n",
    "import re\n",
    "# slugify?\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "from statistics import mean\n",
    "import json\n",
    "import time\n",
    "import unittest\n",
    "\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "\n",
    "# sklearn\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Vizualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED=1234\n",
    "website_prefix = \"https://www.uuu.com\"\n",
    "file_path = \"path\\\\file.csv\" # used in get_import_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global fuctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if there is usefull function, put it there"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Harvesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "   ########## GET DATA FROM SOURCES\n",
    "    \n",
    "    # Scrapp\n",
    "    \n",
    "    # Api\n",
    "    \n",
    "    # Import\n",
    "    \n",
    "    #########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrap the website *** to give a usefull dataframe\n",
    "\n",
    "def get_scrap_dataframe():\n",
    "\n",
    "    # TBD\n",
    "    \"\"\"\n",
    "    # CODE EXAMPLE\n",
    "    \n",
    "    url = website_prefix + \"\" #\n",
    "    soup = _handle_request_result_and_build_soup(url)\n",
    "\n",
    "    specific_class = \"search-table-data\"\n",
    "    tableContent =soup.find(class_=specific_class).find_all(\"tr\")\n",
    "    mylinks =[]\n",
    "    for ind in range (1,len(tableContent)):\n",
    "        mylinks.append(_clear_url(tableContent[ind].attrs['onclick']))\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the *** api to get usefull dataframe\n",
    "\n",
    "def get_api_dataframe():\n",
    "\n",
    "    # TBD\n",
    "    \"\"\"\n",
    "    # CODE EXAMPLE\n",
    "    \n",
    "    # We read the token which is stored in a local file\n",
    "    token = open(\"PATH\\\\gitToken.txt\", encoding=\"utf8\").readline()[:-1]\n",
    "    \n",
    "    request = requests.get(\"https://api.github.com/users/\" + username + \"/repos\", auth=(username_account, token))\n",
    "    #print(\"request code \", request.status_code)\n",
    "    \n",
    "    json_res = json.loads(request.text)\n",
    "    #print(\"jsonres\", json_res)\n",
    "    \n",
    "    try:\n",
    "        star_list = [json1[\"stargazers_count\"] for json1 in json_res]\n",
    "        dict[username] = mean(star_list)\n",
    "    except:\n",
    "        dict[username] = 0\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data from a csv file\n",
    "\n",
    "def get_import_dataframe():\n",
    "\n",
    "    # TBD\n",
    "    \"\"\"\n",
    "    #CODE EXAMPLE \n",
    "    \n",
    "    na_values = ['?', '']\n",
    "    \n",
    "    path = \"path\\\\file.csv\" #dataset insee\n",
    "    \n",
    "    # We import the dataframe\n",
    "    df = pd.read_csv(file_path, sep=',', na_values=na_values) # add chunksize=1000 to limit the size then df = next(df)\n",
    "    \"\"\"\n",
    "\n",
    "    # use the global variable file_path to define the path\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Data joining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the data of the 3 dataframe\n",
    "\n",
    "def get_joined_dataframe(df_scrap, df_api, df_import):\n",
    "    \n",
    "    # TBD\n",
    "    \n",
    "    \"\"\"\n",
    "    # CODE EXAMPLE\n",
    "    \n",
    "    joined_df_with_pop = pd.merge(joined_df, population_filtered, on='DEPARTEMENTID', left_index=True, right_index=False)\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    return df   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the dataframe\n",
    "\n",
    "def get_cleaned_dataframe(df_in):\n",
    "    \n",
    "    # TBD\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    return df  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Vizualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot an interesting thing\n",
    "\n",
    "def vizualise_interesting_thing_1(df_in):\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # CODE EXAMPLE\n",
    "    \n",
    "    plot_pop_depassement = df_in.plot(x='POPULATION', y='POURCENTAGE_DEPASSEMENT', marker='o', color='red', title = \"POPULATION as a function of POURCENTAGE_DEPASSEMENT\")\n",
    "    plt.show()\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results of the model\n",
    "\n",
    "def plot_my_model(model):\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Explotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a model on the data\n",
    "\n",
    "def build_a_model(df_in):\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # CODE EXAMPLE\n",
    "    \n",
    "    X = spe[\"EFFECTIFS/POPULATION\"]\n",
    "    Y = spe[\"POURCENTAGE_DEPASSEMENT\"]\n",
    "\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.2, random_state=SEED)\n",
    "    skl_lm = linear_model.LinearRegression(fit_intercept=True)\n",
    "    skl_lm.fit(X_train, Y_train)\n",
    "    score = skl_lm.score(X_test, Y_test)\n",
    "    print(\"Score: \\n\", score)\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test definition & main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start \n",
      "\n",
      "End \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.009s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "class HackathonTests(unittest.TestCase):\n",
    "\n",
    "    def test_dummy(self):\n",
    "        self.assertEqual('foo'.upper(), 'FOO')\n",
    "        \n",
    "    def test_return_type(self):\n",
    "        self.assertEqual(type(get_scrap_dataframe()), type(pd.DataFrame()))    \n",
    "        self.assertEqual(type(get_api_dataframe()), type(pd.DataFrame()))\n",
    "        self.assertEqual(type(get_import_dataframe()), type(pd.DataFrame()))\n",
    "        self.assertEqual(type(get_joined_dataframe(pd.DataFrame(),pd.DataFrame(),pd.DataFrame())), type(pd.DataFrame()))\n",
    "        self.assertEqual(type(get_cleaned_dataframe(pd.DataFrame())), type(pd.DataFrame()))\n",
    "        self.assertEqual(type(vizualise_interesting_thing_1(pd.DataFrame())), type(None))\n",
    "        self.assertEqual(type(build_a_model(pd.DataFrame())), type(None))\n",
    "        self.assertEqual(type(plot_my_model(pd.DataFrame())), type(None))\n",
    "        \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    unittest.main(argv=['first-arg-is-ignored'], exit=False)\n",
    "\n",
    "def main():\n",
    "    print(\"Start \\n\")\n",
    "\n",
    "\n",
    "    ########## GET DATA FROM SOURCES\n",
    "    \n",
    "    # Scrapp\n",
    "    df_scrap = get_scrap_dataframe()\n",
    "    \n",
    "    # Api\n",
    "    df_api = get_api_dataframe()\n",
    "    \n",
    "    # Import\n",
    "    df_import = get_import_dataframe()\n",
    "    \n",
    "    #########\n",
    "    \n",
    "    \n",
    "    \n",
    "    ########## DATA JOINING\n",
    "    \n",
    "    df_joined = get_joined_dataframe(df_scrap, df_api, df_import)\n",
    "    \n",
    "    \n",
    "    ########\n",
    "    \n",
    "    \n",
    "    ########## DATA CLEANING (after or before join depending on data)\n",
    "    \n",
    "    df_cleaned = get_cleaned_dataframe(df_joined)\n",
    "    \n",
    "    #########\n",
    "    \n",
    "    \n",
    "    ########## DATA VISUALISATION\n",
    "    \n",
    "    vizualise_interesting_thing_1(df_cleaned)\n",
    "    \n",
    "    #########\n",
    "    \n",
    "    ########## DATA EXPLOTATION\n",
    "    \n",
    "    # Use model to predict\n",
    "    \n",
    "    model_built = build_a_model(df_cleaned)\n",
    "    \n",
    "    plot_my_model(model_built)\n",
    "    \n",
    "    \n",
    "    #########\n",
    "    \n",
    "\n",
    "    print(\"End \\n\")\n",
    "\n",
    "\n",
    "main()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
